<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width" />
    <title></title>
    <style>
        body, html { margin: 0; height: 100%; font-size: larger; background:black; color:white }
    </style>
    <script>
        (function () {
            document.addEventListener("DOMContentLoaded", function () {
                let enableVoice = document.getElementById('enable-voice');
                let submitBtn = document.getElementById('submit-button');
                let promptInput = document.getElementById('prompt-input');
                let openaiOutput = document.getElementById('openai-output');
                var msg = new SpeechSynthesisUtterance();
                var voices = window.speechSynthesis.getVoices();

                enableVoice.addEventListener('change', (e) => localStorage.setItem('ENABLE_VOICE', e.target.checked));
                enableVoice.disabled = false;

                var evc = localStorage.getItem('ENABLE_VOICE');
                if (evc === undefined || evc === null) evc = true;
                else enableVoice.checked = (evc === "true") ? true : false;
                
                submitBtn.addEventListener('click', async function () {
                    var token = localStorage.getItem('OPENAI_API_KEY');
                    if (!token || token.length < 10) {
                        token = prompt("Please input OpenAI API key (stored in browser cache)", "");
                        localStorage.setItem('OPENAI_API_KEY', token)
                    }
                    await openAiSend(promptInput, openaiOutput, token);
                });
                handleRecognition(promptInput, submitBtn);
                promptInput.focus();

                function handleRecognition(input, btn, lang = 'en-US', continuous = false) {
                    var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
                    let recognition = new SpeechRecognition();
                    recognition.continuous = continuous;
                    recognition.lang = lang;
                    recognition.interimResults = false;
                    recognition.maxAlternatives = 1;
                    document.body.onclick = (e) => (e.target === document.body && enableVoice.checked) ? recognition.start() : undefined;
                    recognition.onresult = (e) => { input.value = e.results[0][0].transcript; if (btn) btn.click() }
                    recognition.onspeechend = () => recognition.stop(); 
                }

                async function openAiSend(input, output, token) {
                    const response = await fetch('https://api.openai.com/v1/chat/completions', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${token}` },
                        body: JSON.stringify({ model: "gpt-3.5-turbo", temperature: 0.8, stream: true, messages: [{ role: "user", content: input.value }] })
                    });
                    let chatOutput = []
                    const reader = response.body.getReader();
                    while (true) {
                        const { done, value } = await reader.read();
                        if (done) break;
                        const textDecoder = new TextDecoder();
                        const chunk = textDecoder.decode(value, { stream: true });
                        const lines = chunk.split('\n');
                        for (let i in lines) {
                            if (lines[i].length === 0) continue;
                            if (lines[i].startsWith(':')) continue;
                            if (lines[i] === 'data: [DONE]') {
                                if (enableVoice.checked) {
                                    msg.text = output.textContent;
                                    msg.lang = 'en-AU'; //en-US, en-GB, en-CA, en-AU
                                    msg.voice = voices[1];
                                    msg.pitch = 0.5;
                                    msg.rate = 1.25;
                                    window.speechSynthesis.speak(msg);
                                }
                                return;
                            }
                            let json = JSON.parse(lines[i].substring(6));
                            if (json.choices) {
                                chatOutput.push(json.choices[0].delta.content || '')
                                output.textContent = chatOutput.join('');
                            }
                        }
                    }
                }
            });
        })();
    </script>
</head>

<body onbeforeunload="if (window.speechSynthesis.speaking)window.speechSynthesis.cancel()">
    <textarea id="prompt-input" style="width:100vw;height:4em" placeholder="Enter prompt or touch screen for voice prompt"></textarea>
    <div style="text-align:right">
        <input type="checkbox" id="enable-voice" style="width:2em;height:2em">
        <label for="enable-voice">Enable Voice</label>
        <button id="submit-button" style="width:50vw; text-align:center;height:4em; font-weight:bold">Submit</button>
    </div>

    <div id="openai-output" style="white-space:pre-wrap; color: white"></div>



</body>
</html>
